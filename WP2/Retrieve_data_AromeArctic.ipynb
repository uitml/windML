{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1725e3ea",
   "metadata": {},
   "source": [
    "# Download data from AROME-Arctic and save as ncfile\n",
    "\n",
    "The following codes is a guide to download data from the NWP AROME-Arctic extracted at one location with coordinates (Lat/Lon) for a chosen time period and save it as an nc-file, available at https://thredds.met.no/thredds/catalog/aromearcticarchive/catalog.html. This script use the arome_arctic_full files containing several variables.\n",
    "\n",
    "choose a datespan (years, months, days) and save it as a ncfile.\n",
    "\n",
    "Data available from: 2015.10.21 to current date\n",
    "\n",
    "\n",
    "- AROME-Arctic issues deterministic forecasts 4 times a day with a lead time of 66 hours\n",
    "\n",
    "- The model utilises a three-dimensional variational data assimilation with 3-hourly cycling to assimilate conventional observations, scatterometer ocean surface winds, satellite radiances and atmospheric motion vectors.\n",
    "\n",
    "(Source and more informatil about the model: https://www.met.no/en/projects/The-weather-model-AROME-Arctic/about)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "import netCDF4 as nc\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "\n",
    "import pyproj\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import requests\n",
    "from __future__ import print_function\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dfdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The coordinates in get_coordinates is at the center of the offshore wind sites\n",
    "\"\"\"\n",
    "\n",
    "def get_coordinates(location_name):\n",
    "    locations = {\n",
    "        'Nordavind_A': {\n",
    "            'latitude': 71.1314956,\n",
    "            'longitude': 32.048109\n",
    "        },\n",
    "        'Nordavind_B': {\n",
    "            'latitude': 71.7880587,\n",
    "            'longitude': 27.7221338\n",
    "        },\n",
    "        'Nordavind_C': {\n",
    "            'latitude': 71.7471898,\n",
    "            'longitude': 19.9808019\n",
    "        },\n",
    "        'Nordavind_D': {\n",
    "            'latitude': 71.473272,\n",
    "            'longitude': 18.7614613\n",
    "        }\n",
    "        \n",
    "    }\n",
    "\n",
    "    if location_name in locations:\n",
    "        coordinates = locations[location_name]\n",
    "        return coordinates['latitude'], coordinates['longitude']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c03c5",
   "metadata": {},
   "source": [
    "## Seklima station information retrival with frost api \n",
    "\n",
    "[Link to frost webpage](https://frost.met.no/index.html)\n",
    "\n",
    "1. Create client id for yourself \n",
    "    * [Create client id here](https://frost.met.no/auth/requestCredentials.html)\n",
    "    \n",
    "This is used to retrive the longitude and latitude\n",
    "\n",
    "PS: Not all stations are included in the model area. Arome-Arctic project northern areas  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c06972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your own client ID here\n",
    "client_id = 'insert client ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f73ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Getting the data for the meta dataframe\n",
    "\n",
    "Using the frost api for seklima\n",
    "'''\n",
    "\n",
    "endpoint = 'https://frost.met.no/sources/v0.jsonld'\n",
    "\n",
    "# Dictionary with elements to retrieve\n",
    "parameters = {\n",
    "    'fields': 'name,id,geometry,masl'\n",
    "}\n",
    "\n",
    "# Issue an HTTP GET request\n",
    "r = requests.get(endpoint, parameters, auth=(client_id,''))\n",
    "# Extract JSON data\n",
    "json = r.json()\n",
    "\n",
    "# Check if the request worked, print out any errors\n",
    "if r.status_code == 200:\n",
    "    data_exp = json['data']\n",
    "    print('Data retrieved from frost.met.no!')\n",
    "else:\n",
    "    print('Error! Returned status code %s' % r.status_code)\n",
    "    print('Message: %s' % json['error']['message'])\n",
    "    print('Reason: %s' % json['error']['reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transforming the data from a raw json format retrieved by requests \n",
    "to a pandas df format\n",
    "\n",
    "When redefining the query the new columns need to be spesified for the dataframe df\n",
    "'''\n",
    "\n",
    "meta_df = pd.DataFrame(columns=['id', 'name', 'lon', 'lat', 'heigh-asl (m)'])\n",
    "ignored_values = 0\n",
    "for i in range(len(data_exp)):\n",
    "    row = []\n",
    "    try:\n",
    "        row.append(data_exp[i]['id'])\n",
    "        row.append(data_exp[i]['name'])\n",
    "        row.append(data_exp[i]['geometry']['coordinates'][0])\n",
    "        row.append(data_exp[i]['geometry']['coordinates'][1])\n",
    "        row.append(data_exp[i]['masl'])\n",
    "        meta_df.loc[len(meta_df)] = row\n",
    "    except:\n",
    "        ignored_values += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "print(f'Number of discarded values {ignored_values}')\n",
    "\n",
    "# Setting the station id as row index2\n",
    "meta_df = meta_df.set_index('id')\n",
    "\n",
    "display(meta_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce924f6c",
   "metadata": {},
   "source": [
    "- Change station ID to match measurement station to get station coordinates\n",
    "    * Find station ID at ([stations](https://seklima.met.no/stations/))\n",
    " \n",
    "or \n",
    "\n",
    "- Insert site_name to get coordinates from center of OWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beaba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################\n",
    "\n",
    "\n",
    "station_id = \"SN76956\" # insert station ID, ex: 'SN76956' Goliat ,  'SN20926' hjelms√∏ybanken\n",
    "\n",
    "\n",
    "################\n",
    "\n",
    "longitude = meta_df.loc[f\"{station_id}\"][\"lon\"]\n",
    "latitude = meta_df.loc[f\"{station_id}\"][\"lat\"]\n",
    "\n",
    "print(f\"{station_id}: longitude = {longitude}, latitude = {latitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the site name you want the data extracted from\n",
    "\n",
    "################\n",
    "\n",
    "site_name = 'Nordavind_C'\n",
    "\n",
    "################\n",
    "\n",
    "latitude, longitude = get_coordinates_center_OWS(site_name) # gets the latitude and longitude of the chosen site\n",
    "print(f\"{site_name}: longitude = {longitude}, latitude = {latitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df607440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose latitude, longitude\n",
    "\n",
    "latitude = \n",
    "longitude = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0871170",
   "metadata": {},
   "source": [
    "## Projecting coordinates\n",
    "Starts by projecting the chosen Latitude and Longitude coordinate to x and y cooridnates used in the model\n",
    "- No changes needed in this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c44b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load in a random file to project coordinates\n",
    "filename = \"https://thredds.met.no/thredds/dodsC/aromearcticarchive/\"+\\\n",
    "               \"2022/01/01/arome_arctic_full_2_5km_20220101T00Z.nc\"\n",
    "ncfile = nc.Dataset(filename)\n",
    "\n",
    "crs_AA = pyproj.CRS.from_cf(\n",
    "         {\n",
    "            \"grid_mapping_name\": \"lambert_conformal_conic\",\n",
    "            \"standard_parallel\": [77.5, 77.5],\n",
    "            \"longitude_of_central_meridian\": -25.0,\n",
    "            \"latitude_of_projection_origin\": 77.5,\n",
    "             \"earth_radius\": 6371000.0,\n",
    "         }\n",
    ")\n",
    "\n",
    "# Transformer to project from ESPG:4368 (WGS:84) to our lambert_conformal_conic\n",
    "proj = pyproj.Transformer.from_crs(4326,crs_AA,always_xy=True)\n",
    "\n",
    "# Compute projected coordinates of lat/lon point\n",
    "lat = latitude\n",
    "lon = longitude\n",
    "X,Y = proj.transform(lon,lat)\n",
    "\n",
    "# Find nearest neighbour\n",
    "x = ncfile.variables[\"x\"][:]\n",
    "y = ncfile.variables[\"y\"][:]\n",
    "\n",
    "Ix = np.argmin(np.abs(x - X))\n",
    "Iy = np.argmin(np.abs(y - Y))\n",
    "\n",
    "ncfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f45d2a0",
   "metadata": {},
   "source": [
    "## Collecting the data \n",
    "In this section you can choose \"start date\" and \"end date\" for the timeperiod of data to be extracted. \n",
    "\n",
    "Each file contains a forecast of 66 hours. Due to spin-up error this script retrieves data starting 6h-in in each file\n",
    "extracting 3 hours from the file before jumping to next file. The files contains several variables and this scrips acts \n",
    "as an example, other variables can be added or removed by alternating lists and variables. Variables will be extracted from the chosen height (except variables at a given height, ex: surface_air_pressure)\n",
    "\n",
    "\n",
    "* Change start_date and end_date\n",
    "* Choose hyrbid level (height)\n",
    "* Change empty lists and extracted variables\n",
    "\n",
    "- PS: x_wind and y_wind is relativ to model, not rotated to cardinal directions. \n",
    "- (Rotation to cardinal direction is done by using the alpha.nc file)\n",
    "\n",
    "time to collect ?? months; approx ?? min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ecb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################\n",
    "\n",
    "start_date = date(2021, 12, 31) # choose start date (year, month, day)\n",
    "end_date = date(2022, 12, 31) # choose end date (year, month, day)\n",
    "\n",
    "delta = timedelta(days=1) # delta (timestep), default set to 1 day\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Choose a hybrid level [64 to 0]:\n",
    "64 = 0 masl\n",
    "63 = 24 masl\n",
    "62 = 48 masl\n",
    "61 = 73 masl\n",
    "60 = 99 masl\n",
    "59 = 127 masl\n",
    "58 = 156 masl\n",
    "57 = 187 masl\n",
    "56 = 221 masl\n",
    "55 = 259 masl\n",
    "\"\"\"\n",
    "\n",
    "hybrid_lvl = 62   # 64 surface, 0 ToA \n",
    "\n",
    "######################\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create empty lists for each variable to be extracted\n",
    "\"\"\"\n",
    "\n",
    "time = []\n",
    "air_temp=[]\n",
    "x_wind = []\n",
    "y_wind = []\n",
    "surface_air_pressure = []\n",
    "\n",
    "\n",
    "hours = [\"00\", \"03\", \"06\", \"09\", \"12\", \"15\", \"18\", \"21\"]\n",
    "\n",
    "while start_date <= end_date:\n",
    "    y = start_date.strftime(\"%Y\")\n",
    "    m = start_date.strftime(\"%m\")\n",
    "    d = start_date.strftime(\"%d\")\n",
    "    \n",
    "    for i in hours:\n",
    "        opendap_url = f\"https://thredds.met.no/thredds/dodsC/aromearcticarchive/{y}/{m}/{d}/arome_arctic_full_2_5km_{y}{m}{d}T{i}Z.nc\"\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Extract variables \n",
    "            ncfile = nc.Dataset(opendap_url)\n",
    "            times = ncfile.variables[\"time\"][6:9]\n",
    "            airtemp = ncfile.variables[\"air_temperature_ml\"][6:9, hybrid_lvl, Iy, Ix]\n",
    "            xwind = ncfile.variables[\"x_wind_ml\"][6:9, hybrid_lvl, Iy, Ix]\n",
    "            ywind = ncfile.variables[\"y_wind_ml\"][6:9, hybrid_lvl, Iy, Ix]\n",
    "            sur_p = ncfile.variables[\"surface_air_pressure\"][6:9, 0, Iy, Ix]\n",
    "            \n",
    "            # Add variables to lists\n",
    "            time.extend(times)\n",
    "            air_temp.extend(airtemp)\n",
    "            x_wind.extend(xwind)\n",
    "            y_wind.extend(ywind)\n",
    "            surface_air_pressure.extend(sur_p)\n",
    "            \n",
    "            ncfile.close()\n",
    "        except Exception as e: # sometimes files for 1 day are missing spesific hours, this skipps to next file \n",
    "            # If opendap_url is not found or any other exception occurs, skip to the next hour\n",
    "            print(f\"Skipping hour {i} of date {y}-{m}-{d} due to exception: {e}\")\n",
    "            continue\n",
    "\n",
    "    start_date += delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf8e20",
   "metadata": {},
   "source": [
    "### Rotating wind with Alpha\n",
    "This section uses the alpha.nc file with rotated local grid in every location. alpha.nc is created by running a seperate code, this needs to be done before running the following.\n",
    "- This section rotates wind into cardinal directions before saving the file. This can also be skipped in this step and be done when processing the final ncfile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x-y to cardinal direction and speed\n",
    "\n",
    "\n",
    "# Open alpha.nc with rotated local grids and extract alpha from Iy and Ix\n",
    "ncfile = nc.Dataset(\"alpha.nc\")\n",
    "\n",
    "alpha = ncfile.variables[\"alpha\"][Iy, Ix]\n",
    "\n",
    "\n",
    "\n",
    "# Wind direction relative to Earth (wdir) may be calculated as follows:\n",
    "#   wdir = alpha + 90-atan2(v,u)\n",
    "# where u and v are model wind relative to model grid\n",
    "\n",
    "wdir = []\n",
    "ws = []\n",
    "\n",
    "for i in range(0,len(x_wind)):\n",
    "    w = alpha + (90-np.arctan2(y_wind[i], x_wind[i]))\n",
    "    wdir.append(w)\n",
    "    \n",
    "    speed = np.sqrt(x_wind[i]**2 + y_wind[i]**2)\n",
    "    ws.append(speed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33033f",
   "metadata": {},
   "source": [
    "## Dictionary\n",
    "The output from collecting data is stored in lists. This section creates an dictionary and uses pandas to store in a easy-reference system\n",
    "- Changes can be made in the dictionary \"d_data\" if variables are ignored or added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary and give name to the lists\n",
    "d_data = {\n",
    "     \"time\" : time, \n",
    "     f\"air_temperature_Hyb:{hybrid_lvl}\": air_temp,\n",
    "     \"surface_pressure\": surface_air_pressure,\n",
    "     f\"x_wind_Hyb:{hybrid_lvl}\": x_wind,\n",
    "     f\"y_wind_Hyb:{hybrid_lvl}\": y_wind,\n",
    "     f\"wind_speed\": ws,\n",
    "     f\"wind_direction\": wdir\n",
    "}\n",
    "\n",
    "\n",
    "# convert to pandas dataframe\n",
    "\n",
    "weather_data = pd.DataFrame.from_dict(d_data)\n",
    "weather_data = weather_data.set_index('time')\n",
    "\n",
    "display(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238863f2",
   "metadata": {},
   "source": [
    "## Save as NC-file\n",
    "Define a function that saves the \"weather_data\" as an nc-file. \n",
    "- Change the output_filename to desired new saved filename\n",
    "\n",
    "Filesize for time, wind speed and wind direction for ?? months: ?? KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is an easy option saving the new file directly in the same directory as the working directory\n",
    "\"\"\"\n",
    "\n",
    "def save_dataframe_to_netcdf(dataframe, output_file):\n",
    "    dataset = xr.Dataset(data_vars=dataframe.to_dict('series'))\n",
    "    dataset.to_netcdf(output_file)\n",
    "\n",
    "    print(f\"Data saved successfully to {output_file}.\")\n",
    "\n",
    "\n",
    "\n",
    "output_filename = 'AROME_dir13_weather_data.nc' #choose filename: default: \"AROME_weather_data.nc\"\n",
    "\n",
    "save_dataframe_to_netcdf(weather_data, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code makes a new optional directory at a desired location and saves the new file in this new directory.\n",
    "If the directory already exist it will just save the new file in that directory. This way different ncfiles can be saved\n",
    "in the same directory by keeping the same directory name and changing only the output_filename\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "# New directory \n",
    "directory = \"weather_data_NORA3\"\n",
    "  \n",
    "# Parent Directory path \n",
    "parent_dir = \"C:/Users/Ida/\"\n",
    "\n",
    "# Filename new ncfile\n",
    "# {site_name} or {station_id}\n",
    "output_filename = 'AROME2_weather_data.nc' #choose filename: default: \"weather_data_NORA3.nc\"\n",
    "\n",
    "\n",
    "# Path \n",
    "path = os.path.join(parent_dir, directory) \n",
    "  \n",
    "# Create the directory if not already existing\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "\n",
    "def save_dataframe_to_netcdf(dataframe, output_file):\n",
    "    dataset = xr.Dataset(data_vars=dataframe.to_dict('series'))\n",
    "    output_path = f\"{parent_dir}{directory}/{output_file}\"\n",
    "    dataset.to_netcdf(output_path)\n",
    "\n",
    "    print(f\"Data saved successfully to {output_path}.\")\n",
    "\n",
    "\n",
    "save_dataframe_to_netcdf(weather_data, output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
